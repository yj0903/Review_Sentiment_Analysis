{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install konlpy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from konlpy.tag import Okt\n",
    "import nltk\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fashion = pd.read_csv(\"../data/01. 패션.csv\", encoding='utf-8', sep=\",\")\n",
    "df_cosmetic = pd.read_csv(\"../data/02. 화장품.csv\", encoding='utf-8', sep=\",\")\n",
    "df_appliance = pd.read_csv(\"../data/03. 가전.csv\", encoding='utf-8', sep=\",\")\n",
    "df_it = pd.read_csv(\"../data/04. IT기기.csv\", encoding='utf-8', sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>RawText</th>\n",
       "      <th>Source</th>\n",
       "      <th>Domain</th>\n",
       "      <th>MainCategory</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>ReviewScore</th>\n",
       "      <th>Syllable</th>\n",
       "      <th>Word</th>\n",
       "      <th>RDate</th>\n",
       "      <th>Aspects</th>\n",
       "      <th>GeneralPolarity</th>\n",
       "      <th>label</th>\n",
       "      <th>Score_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3761</td>\n",
       "      <td>제품 만족합니다. 디자인이 깔끔하고 멋스럽네요. 배송도 빠르고 좋아요.^^ 생각보다...</td>\n",
       "      <td>SNS</td>\n",
       "      <td>IT기기</td>\n",
       "      <td>컴퓨터/주변기기</td>\n",
       "      <td>펠로우즈 레더렛 메모리폼 손목받침대 (91825)</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>18</td>\n",
       "      <td>20220304</td>\n",
       "      <td>[{'Aspect': '디자인', 'SentimentText': '디자인이 깔끔하고...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3762</td>\n",
       "      <td>가격대비! 좋아요! 음량도 크고! 구매하세요</td>\n",
       "      <td>SNS</td>\n",
       "      <td>IT기기</td>\n",
       "      <td>컴퓨터/주변기기</td>\n",
       "      <td>[엠피지오]소나보스/사운드바 스피커/PC스피커/컴퓨터스피커/2채널/USB전원</td>\n",
       "      <td>80</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>20210826</td>\n",
       "      <td>[{'Aspect': '가격', 'SentimentText': '가격대비! 좋아요!...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3763</td>\n",
       "      <td>화질도 괜찮고 타사 제품에 비해 길이가 1M정도 더 길어서 좋아요</td>\n",
       "      <td>SNS</td>\n",
       "      <td>IT기기</td>\n",
       "      <td>컴퓨터/주변기기</td>\n",
       "      <td>플레오맥스 PM-MC1000 C타입 to HDMI 미러링케이블 4K UHD 유료미디...</td>\n",
       "      <td>100</td>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "      <td>20210330</td>\n",
       "      <td>[{'Aspect': '화질', 'SentimentText': '화질도 괜찮고 ',...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>입학축하선물로 노트북 뭘 살지 이것저것 다 찾아보다가, 결국 OOOO 22형으로 주...</td>\n",
       "      <td>SNS</td>\n",
       "      <td>IT기기</td>\n",
       "      <td>컴퓨터/주변기기</td>\n",
       "      <td>[22년 신모델]  LG그램 15Z95P-GA5LK (i5-1155G7/16GB/...</td>\n",
       "      <td>100</td>\n",
       "      <td>165</td>\n",
       "      <td>30</td>\n",
       "      <td>20220205</td>\n",
       "      <td>[{'Aspect': '제조일/제조사', 'SentimentText': '역시 명불...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3765</td>\n",
       "      <td>생각보다 상당히 빨리 받았네요. OO에서 직접 배송해주는거라 설치 기사가 직접 배송...</td>\n",
       "      <td>SNS</td>\n",
       "      <td>IT기기</td>\n",
       "      <td>컴퓨터/주변기기</td>\n",
       "      <td>(1TB 외장하드 패키지)삼성직배송/설치 고성능 프리미엄 노트북 Pen NT 930...</td>\n",
       "      <td>100</td>\n",
       "      <td>214</td>\n",
       "      <td>50</td>\n",
       "      <td>20180107</td>\n",
       "      <td>[{'Aspect': '기능', 'SentimentText': '성능 또한 상당히 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            RawText Source Domain  \\\n",
       "0   3761  제품 만족합니다. 디자인이 깔끔하고 멋스럽네요. 배송도 빠르고 좋아요.^^ 생각보다...    SNS   IT기기   \n",
       "1   3762                           가격대비! 좋아요! 음량도 크고! 구매하세요    SNS   IT기기   \n",
       "2   3763               화질도 괜찮고 타사 제품에 비해 길이가 1M정도 더 길어서 좋아요    SNS   IT기기   \n",
       "3   3764  입학축하선물로 노트북 뭘 살지 이것저것 다 찾아보다가, 결국 OOOO 22형으로 주...    SNS   IT기기   \n",
       "4   3765  생각보다 상당히 빨리 받았네요. OO에서 직접 배송해주는거라 설치 기사가 직접 배송...    SNS   IT기기   \n",
       "\n",
       "  MainCategory                                        ProductName  \\\n",
       "0     컴퓨터/주변기기                        펠로우즈 레더렛 메모리폼 손목받침대 (91825)   \n",
       "1     컴퓨터/주변기기         [엠피지오]소나보스/사운드바 스피커/PC스피커/컴퓨터스피커/2채널/USB전원   \n",
       "2     컴퓨터/주변기기  플레오맥스 PM-MC1000 C타입 to HDMI 미러링케이블 4K UHD 유료미디...   \n",
       "3     컴퓨터/주변기기   [22년 신모델]  LG그램 15Z95P-GA5LK (i5-1155G7/16GB/...   \n",
       "4     컴퓨터/주변기기  (1TB 외장하드 패키지)삼성직배송/설치 고성능 프리미엄 노트북 Pen NT 930...   \n",
       "\n",
       "   ReviewScore  Syllable  Word     RDate  \\\n",
       "0          100        90    18  20220304   \n",
       "1           80        24     5  20210826   \n",
       "2          100        36    10  20210330   \n",
       "3          100       165    30  20220205   \n",
       "4          100       214    50  20180107   \n",
       "\n",
       "                                             Aspects  GeneralPolarity  label  \\\n",
       "0  [{'Aspect': '디자인', 'SentimentText': '디자인이 깔끔하고...              NaN      1   \n",
       "1  [{'Aspect': '가격', 'SentimentText': '가격대비! 좋아요!...              1.0      1   \n",
       "2  [{'Aspect': '화질', 'SentimentText': '화질도 괜찮고 ',...              1.0      1   \n",
       "3  [{'Aspect': '제조일/제조사', 'SentimentText': '역시 명불...              NaN      1   \n",
       "4  [{'Aspect': '기능', 'SentimentText': '성능 또한 상당히 ...              0.0      1   \n",
       "\n",
       "   Score_change  \n",
       "0           5.0  \n",
       "1           4.0  \n",
       "2           5.0  \n",
       "3           5.0  \n",
       "4           5.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_it\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label 은 평점 기준으로 긍정이면 1, 부정이면 0으로 라벨링 지정\n",
    "\n",
    "#### 학습용 데이터로 가공\n",
    "- 평점 8 이상 혹은 3 이하만 저장 (8 이상: 긍정적, 3 이하: 부정적)\n",
    "- 각 text를 tokenize한 후, 동사, 형용사, 명사만 저장 (konlpy의 Okt 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ReviewScore 80, 4 이상 긍정적, 50이하, 2이하 부정적으로 지정\n",
    "\n",
    "def tokenize_korean_text(text): \n",
    "  text_filtered = re.sub('[^,.?!\\w\\s]','', text)\n",
    "\n",
    "  okt = Okt() \n",
    "  Okt_morphs = okt.pos(text_filtered) \n",
    "\n",
    "  words = []\n",
    "  for word, pos in Okt_morphs:\n",
    "    if pos == 'Adjective' or pos == 'Verb' or pos == 'Noun':\n",
    "      words.append(word)\n",
    "\n",
    "  words_str = ' '.join(words)\n",
    "  return words_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터전처리 \n",
    "- 점수 기준 긍/부정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Score_change'] = df['ReviewScore'].replace({100:5,90:4.5,80:4.0,70:3.5,60:3.0,50:2.5,40:2.0,30:1.5,20:1.0,10:0.5,0:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['label'] == 0\n",
    "# 긍부정 나누는 label 생성, 점수 3 이상 긍정 3 미만 부정 / 점수 70이상 긍정 그 미만 부정 \n",
    "df['label'] = df['Score_change'].apply(lambda x: 1 if x > 3.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>RawText</th>\n",
       "      <th>Source</th>\n",
       "      <th>Domain</th>\n",
       "      <th>MainCategory</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>ReviewScore</th>\n",
       "      <th>Syllable</th>\n",
       "      <th>Word</th>\n",
       "      <th>RDate</th>\n",
       "      <th>Aspects</th>\n",
       "      <th>GeneralPolarity</th>\n",
       "      <th>label</th>\n",
       "      <th>Score_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3761</td>\n",
       "      <td>제품 만족합니다. 디자인이 깔끔하고 멋스럽네요. 배송도 빠르고 좋아요.^^ 생각보다...</td>\n",
       "      <td>SNS</td>\n",
       "      <td>IT기기</td>\n",
       "      <td>컴퓨터/주변기기</td>\n",
       "      <td>펠로우즈 레더렛 메모리폼 손목받침대 (91825)</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>18</td>\n",
       "      <td>20220304</td>\n",
       "      <td>[{'Aspect': '디자인', 'SentimentText': '디자인이 깔끔하고...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3762</td>\n",
       "      <td>가격대비! 좋아요! 음량도 크고! 구매하세요</td>\n",
       "      <td>SNS</td>\n",
       "      <td>IT기기</td>\n",
       "      <td>컴퓨터/주변기기</td>\n",
       "      <td>[엠피지오]소나보스/사운드바 스피커/PC스피커/컴퓨터스피커/2채널/USB전원</td>\n",
       "      <td>80</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>20210826</td>\n",
       "      <td>[{'Aspect': '가격', 'SentimentText': '가격대비! 좋아요!...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3763</td>\n",
       "      <td>화질도 괜찮고 타사 제품에 비해 길이가 1M정도 더 길어서 좋아요</td>\n",
       "      <td>SNS</td>\n",
       "      <td>IT기기</td>\n",
       "      <td>컴퓨터/주변기기</td>\n",
       "      <td>플레오맥스 PM-MC1000 C타입 to HDMI 미러링케이블 4K UHD 유료미디...</td>\n",
       "      <td>100</td>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "      <td>20210330</td>\n",
       "      <td>[{'Aspect': '화질', 'SentimentText': '화질도 괜찮고 ',...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>입학축하선물로 노트북 뭘 살지 이것저것 다 찾아보다가, 결국 OOOO 22형으로 주...</td>\n",
       "      <td>SNS</td>\n",
       "      <td>IT기기</td>\n",
       "      <td>컴퓨터/주변기기</td>\n",
       "      <td>[22년 신모델]  LG그램 15Z95P-GA5LK (i5-1155G7/16GB/...</td>\n",
       "      <td>100</td>\n",
       "      <td>165</td>\n",
       "      <td>30</td>\n",
       "      <td>20220205</td>\n",
       "      <td>[{'Aspect': '제조일/제조사', 'SentimentText': '역시 명불...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3765</td>\n",
       "      <td>생각보다 상당히 빨리 받았네요. OO에서 직접 배송해주는거라 설치 기사가 직접 배송...</td>\n",
       "      <td>SNS</td>\n",
       "      <td>IT기기</td>\n",
       "      <td>컴퓨터/주변기기</td>\n",
       "      <td>(1TB 외장하드 패키지)삼성직배송/설치 고성능 프리미엄 노트북 Pen NT 930...</td>\n",
       "      <td>100</td>\n",
       "      <td>214</td>\n",
       "      <td>50</td>\n",
       "      <td>20180107</td>\n",
       "      <td>[{'Aspect': '기능', 'SentimentText': '성능 또한 상당히 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            RawText Source Domain  \\\n",
       "0   3761  제품 만족합니다. 디자인이 깔끔하고 멋스럽네요. 배송도 빠르고 좋아요.^^ 생각보다...    SNS   IT기기   \n",
       "1   3762                           가격대비! 좋아요! 음량도 크고! 구매하세요    SNS   IT기기   \n",
       "2   3763               화질도 괜찮고 타사 제품에 비해 길이가 1M정도 더 길어서 좋아요    SNS   IT기기   \n",
       "3   3764  입학축하선물로 노트북 뭘 살지 이것저것 다 찾아보다가, 결국 OOOO 22형으로 주...    SNS   IT기기   \n",
       "4   3765  생각보다 상당히 빨리 받았네요. OO에서 직접 배송해주는거라 설치 기사가 직접 배송...    SNS   IT기기   \n",
       "\n",
       "  MainCategory                                        ProductName  \\\n",
       "0     컴퓨터/주변기기                        펠로우즈 레더렛 메모리폼 손목받침대 (91825)   \n",
       "1     컴퓨터/주변기기         [엠피지오]소나보스/사운드바 스피커/PC스피커/컴퓨터스피커/2채널/USB전원   \n",
       "2     컴퓨터/주변기기  플레오맥스 PM-MC1000 C타입 to HDMI 미러링케이블 4K UHD 유료미디...   \n",
       "3     컴퓨터/주변기기   [22년 신모델]  LG그램 15Z95P-GA5LK (i5-1155G7/16GB/...   \n",
       "4     컴퓨터/주변기기  (1TB 외장하드 패키지)삼성직배송/설치 고성능 프리미엄 노트북 Pen NT 930...   \n",
       "\n",
       "   ReviewScore  Syllable  Word     RDate  \\\n",
       "0          100        90    18  20220304   \n",
       "1           80        24     5  20210826   \n",
       "2          100        36    10  20210330   \n",
       "3          100       165    30  20220205   \n",
       "4          100       214    50  20180107   \n",
       "\n",
       "                                             Aspects  GeneralPolarity  label  \\\n",
       "0  [{'Aspect': '디자인', 'SentimentText': '디자인이 깔끔하고...              NaN      1   \n",
       "1  [{'Aspect': '가격', 'SentimentText': '가격대비! 좋아요!...              1.0      1   \n",
       "2  [{'Aspect': '화질', 'SentimentText': '화질도 괜찮고 ',...              1.0      1   \n",
       "3  [{'Aspect': '제조일/제조사', 'SentimentText': '역시 명불...              NaN      1   \n",
       "4  [{'Aspect': '기능', 'SentimentText': '성능 또한 상당히 ...              0.0      1   \n",
       "\n",
       "   Score_change  \n",
       "0           5.0  \n",
       "1           4.0  \n",
       "2           5.0  \n",
       "3           5.0  \n",
       "4           5.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aaa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m X_texts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m aaa\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m Score_change, RawText \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScore_change\u001b[39m\u001b[38;5;124m'\u001b[39m], df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRawText\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m      6\u001b[0m   tokenized_comment \u001b[38;5;241m=\u001b[39m tokenize_korean_text(RawText)  \u001b[38;5;66;03m# 위에서 만들었던 함수로 comment 쪼개기\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'aaa' is not defined"
     ]
    }
   ],
   "source": [
    "X_texts = []\n",
    "y = []\n",
    "\n",
    "aaa\n",
    "for Score_change, RawText in zip(df['Score_change'], df['RawText']):\n",
    "  tokenized_comment = tokenize_korean_text(RawText)  # 위에서 만들었던 함수로 comment 쪼개기\n",
    "  X_texts.append(tokenized_comment)\n",
    "  y.append(1 if Score_change > 3.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원래 text 수: 41357\n",
      "평점 4이상 텍스트 수: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'원래 text 수: {len(df)}')\n",
    "print(f'평점 4이상 텍스트 수: {len(X_texts)}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>RawText</th>\n",
       "      <th>Source</th>\n",
       "      <th>Domain</th>\n",
       "      <th>MainCategory</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>ReviewScore</th>\n",
       "      <th>Syllable</th>\n",
       "      <th>Word</th>\n",
       "      <th>RDate</th>\n",
       "      <th>Aspects</th>\n",
       "      <th>GeneralPolarity</th>\n",
       "      <th>label</th>\n",
       "      <th>Score_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3761</td>\n",
       "      <td>제품 만족합니다. 디자인이 깔끔하고 멋스럽네요. 배송도 빠르고 좋아요.^^ 생각보다...</td>\n",
       "      <td>SNS</td>\n",
       "      <td>IT기기</td>\n",
       "      <td>컴퓨터/주변기기</td>\n",
       "      <td>펠로우즈 레더렛 메모리폼 손목받침대 (91825)</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>18</td>\n",
       "      <td>20220304</td>\n",
       "      <td>[{'Aspect': '디자인', 'SentimentText': '디자인이 깔끔하고...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            RawText Source Domain  \\\n",
       "0   3761  제품 만족합니다. 디자인이 깔끔하고 멋스럽네요. 배송도 빠르고 좋아요.^^ 생각보다...    SNS   IT기기   \n",
       "\n",
       "  MainCategory                  ProductName  ReviewScore  Syllable  Word  \\\n",
       "0     컴퓨터/주변기기  펠로우즈 레더렛 메모리폼 손목받침대 (91825)          100        90    18   \n",
       "\n",
       "      RDate                                            Aspects  \\\n",
       "0  20220304  [{'Aspect': '디자인', 'SentimentText': '디자인이 깔끔하고...   \n",
       "\n",
       "   GeneralPolarity  label  Score_change  \n",
       "0              NaN      1           5.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='label', data=df)\n",
    "plt.title('negative: 0, positive: 1')\n",
    "plt.xlabel('label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "X_train_texts, X_test_texts, y_train, y_test = train_test_split(X_texts, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer로 vector화\n",
    "tf_vectorizer = CountVectorizer(min_df=1, ngram_range=(1,1))\n",
    "X_train_tf = tf_vectorizer.fit_transform(X_train_texts)  # training data에 맞게 fit & training data를 transform\n",
    "X_test_tf = tf_vectorizer.transform(X_test_texts) # test data를 transform\n",
    "\n",
    "vocablist = [word for word, number in sorted(tf_vectorizer.vocabulary_.items(), key=lambda x:x[1])]  # 단어들을 번호 기준 내림차순으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 11360)\t1\n",
      "  (0, 21535)\t1\n",
      "  (0, 6419)\t1\n",
      "  (0, 22981)\t1\n",
      "  (0, 23212)\t1\n",
      "  (0, 8941)\t1\n",
      "  (0, 15590)\t1\n",
      "  (0, 17059)\t1\n",
      "  (0, 4749)\t1 \n",
      "\n",
      "  (0, 5913)\t1\n",
      "  (0, 5932)\t1\n",
      "  (0, 6928)\t1\n",
      "  (0, 7285)\t1\n",
      "  (0, 10136)\t1\n",
      "  (0, 11862)\t1\n",
      "  (0, 13637)\t1\n",
      "  (0, 16812)\t1\n",
      "  (0, 17017)\t1\n",
      "  (0, 17558)\t1\n",
      "  (0, 17746)\t1 \n",
      "\n",
      "['가가', '가게', '가격']\n"
     ]
    }
   ],
   "source": [
    "## 확인해보기\n",
    "print(X_train_tf[:1], '\\n')\n",
    "print(X_test_tf[:1], '\\n')\n",
    "print(vocablist[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.1, random_state=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(C=0.1, penalty='l2', random_state=0)\n",
    "logistic_model.fit(X_train_tf, y_train)  # 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.1, random_state=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 472 out of 8272\n",
      "Accuracy: 0.9429400386847195\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = logistic_model.predict(X_test_tf)\n",
    "\n",
    "print('Misclassified samples: {} out of {}'.format((y_test_pred != y_test).sum(), len(y_test)))\n",
    "# print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_test_pred)))  # model.score(X_test_tf, y_test)로 계산해도 됨\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_test_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1    8192\n",
      "-1      80\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_pred_series = pd.Series(y_test_pred)\n",
    "value_counts = y_pred_series.value_counts()\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정적인 단어 Top 10 (높은 평점과 상관관계가 강한 단어들)\n",
      "최고(0.830)\n",
      "좋아요(0.768)\n",
      "좋습니다(0.766)\n",
      "만족해요(0.743)\n",
      "좋네요(0.726)\n",
      "만족(0.669)\n",
      "만족합니다(0.660)\n",
      "만족스러워요(0.641)\n",
      "감사해요(0.625)\n",
      "감사합니다(0.604)\n",
      "\n",
      "부정적인 단어 Top 10 (낮은 평점과 상관관계가 강한 단어들)\n",
      "화나네요(-0.680)\n",
      "안되서(-0.684)\n",
      "별로(-0.695)\n",
      "불만족(-0.736)\n",
      "비추(-0.753)\n",
      "반품(-0.762)\n",
      "짜증나네요(-0.792)\n",
      "안되고(-0.818)\n",
      "실망(-1.053)\n",
      "최악(-1.086)\n"
     ]
    }
   ],
   "source": [
    "coefficients = logistic_model.coef_.tolist()\n",
    "\n",
    "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
    "# coefficients(계수)가 큰 값부터 내림차순으로 정렬\n",
    "\n",
    "print('긍정적인 단어 Top 10 (높은 평점과 상관관계가 강한 단어들)')\n",
    "for word_num, coef in sorted_coefficients[:10]:\n",
    "  print('{0:}({1:.3f})'.format(vocablist[word_num], coef))\n",
    "\n",
    "print('\\n부정적인 단어 Top 10 (낮은 평점과 상관관계가 강한 단어들)')\n",
    "for word_num, coef in sorted_coefficients[-10:]: \n",
    "  print('{0:}({1:.3f})'.format(vocablist[word_num], coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긍정/부정 테스트용 함수 생성\n",
    "def guess_good_or_bad(model, text):\n",
    "    text_filtered = text.replace('.', '').replace(',', '').replace(\"'\", \"\").replace('·', ' ').replace('=', '')\n",
    "    okt = Okt()  # Corrected line\n",
    "    Okt_morphs = okt.pos(text_filtered)\n",
    "\n",
    "    words = []\n",
    "    for word, pos in Okt_morphs:\n",
    "        if pos == 'Adjective' or pos == 'Verb' or pos == 'Noun':\n",
    "            words.append(word)\n",
    "    words_str = ' '.join(words)\n",
    "\n",
    "    # Assuming you have defined tf_vectorizer and model somewhere in your code\n",
    "    new_text_tf = tf_vectorizer.transform([words_str])\n",
    "    \n",
    "    result = model.predict(new_text_tf)[0]\n",
    "\n",
    "    if result == 1:\n",
    "        print('긍정')\n",
    "    else:\n",
    "        print('부정')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부정\n"
     ]
    }
   ],
   "source": [
    "guess_good_or_bad(logistic_model, '안되서 화나네요 최악입니다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정\n"
     ]
    }
   ],
   "source": [
    "guess_good_or_bad(logistic_model, '좋아요 최고')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_filename = 'logistic_model.joblib'\n",
    "vectorizer_filename = 'vectorizer.joblib'\n",
    "joblib.dump(logistic_model, model_filename)\n",
    "joblib.dump(tf_vectorizer, vectorizer_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 나이브베이즈 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.940522243713733\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_model = MultinomialNB()\n",
    "naive_bayes_model.fit(X_train_tf, y_train)  # 학습\n",
    "y_test_pred = naive_bayes_model.predict(X_test_tf)\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1    8052\n",
      "-1     220\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_pred_series = pd.Series(y_test_pred)\n",
    "value_counts = y_pred_series.value_counts()\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정적인 단어 Top 10 (높은 평점과 상관관계가 강한 단어들)\n",
      "감사해요: 3.818\n",
      "감사합니다: 3.467\n",
      "다니기: 2.876\n",
      "안심: 2.870\n",
      "편리하고: 2.822\n",
      "꼼꼼하게: 2.690\n",
      "매력: 2.654\n",
      "이쁩니다: 2.639\n",
      "효율: 2.570\n",
      "기뻐요: 2.562\n",
      "\n",
      "부정적인 단어 Top 10 (낮은 평점과 상관관계가 강한 단어들)\n",
      "받지도: -3.652\n",
      "보내라: -3.652\n",
      "빵점: -3.652\n",
      "억지로: -3.652\n",
      "인쇄물: -3.652\n",
      "참조: -3.652\n",
      "못잡고: -3.876\n",
      "성질: -3.876\n",
      "저장장치: -3.876\n",
      "콜센터: -3.876\n"
     ]
    }
   ],
   "source": [
    "# Access feature log probabilities\n",
    "feature_log_probs = naive_bayes_model.feature_log_prob_\n",
    "\n",
    "# Calculate the difference between positive and negative log probabilities\n",
    "log_prob_diff = feature_log_probs[1] - feature_log_probs[0]\n",
    "\n",
    "# Create a list of (word, log_prob_diff) tuples\n",
    "word_log_prob_diff = list(zip(vocablist, log_prob_diff))\n",
    "\n",
    "# Sort the list by log_prob_diff in descending order\n",
    "sorted_word_log_prob_diff = sorted(word_log_prob_diff, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print('긍정적인 단어 Top 10 (높은 평점과 상관관계가 강한 단어들)')\n",
    "for word, log_prob_diff in sorted_word_log_prob_diff[:10]:\n",
    "    print('{0}: {1:.3f}'.format(word, log_prob_diff))\n",
    "\n",
    "print('\\n부정적인 단어 Top 10 (낮은 평점과 상관관계가 강한 단어들)')\n",
    "for word, log_prob_diff in sorted_word_log_prob_diff[-10:]:\n",
    "    print('{0}: {1:.3f}'.format(word, log_prob_diff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정\n"
     ]
    }
   ],
   "source": [
    "guess_good_or_bad(naive_bayes_model, '좋아요 최고')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_good_or_bad(naive_bayes_model, '좋아요 최고')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.joblib']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_filename = 'naive_bayes_model.joblib'\n",
    "vectorizer_filename = 'vectorizer.joblib'\n",
    "joblib.dump(naive_bayes_model, model_filename)\n",
    "joblib.dump(tf_vectorizer, vectorizer_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 토크나이저를 불러온다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>RawText</th>\n",
       "      <th>Source</th>\n",
       "      <th>Domain</th>\n",
       "      <th>MainCategory</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>ReviewScore</th>\n",
       "      <th>Syllable</th>\n",
       "      <th>Word</th>\n",
       "      <th>RDate</th>\n",
       "      <th>Aspects</th>\n",
       "      <th>GeneralPolarity</th>\n",
       "      <th>label</th>\n",
       "      <th>Score_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3761</td>\n",
       "      <td>제품 만족합니다. 디자인이 깔끔하고 멋스럽네요. 배송도 빠르고 좋아요.^^ 생각보다...</td>\n",
       "      <td>SNS</td>\n",
       "      <td>IT기기</td>\n",
       "      <td>컴퓨터/주변기기</td>\n",
       "      <td>펠로우즈 레더렛 메모리폼 손목받침대 (91825)</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>18</td>\n",
       "      <td>20220304</td>\n",
       "      <td>[{'Aspect': '디자인', 'SentimentText': '디자인이 깔끔하고...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            RawText Source Domain  \\\n",
       "0   3761  제품 만족합니다. 디자인이 깔끔하고 멋스럽네요. 배송도 빠르고 좋아요.^^ 생각보다...    SNS   IT기기   \n",
       "\n",
       "  MainCategory                  ProductName  ReviewScore  Syllable  Word  \\\n",
       "0     컴퓨터/주변기기  펠로우즈 레더렛 메모리폼 손목받침대 (91825)          100        90    18   \n",
       "\n",
       "      RDate                                            Aspects  \\\n",
       "0  20220304  [{'Aspect': '디자인', 'SentimentText': '디자인이 깔끔하고...   \n",
       "\n",
       "   GeneralPolarity  label  Score_change  \n",
       "0              NaN      1           5.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33085,), (8272,), (33085,), (8272,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_test_split\n",
    "X_train_texts, X_test_texts, y_train, y_test = train_test_split(df['RawText'], df['label'], test_size=0.2, random_state=0)\n",
    "\n",
    "# 레이블을 정수형으로 변환\n",
    "y_train = [int(label) for label in y_train]\n",
    "y_test = [int(label) for label in y_test]\n",
    "\n",
    "# 레이블을 넘파이 배열로 변환\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "X_train_texts.shape, X_test_texts.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(data, tokenizer):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    token_type_ids = []\n",
    " \n",
    "    for text in data:\n",
    "        tokenized_text = tokenizer.encode_plus(text,\n",
    "                                            max_length=50,\n",
    "                                            add_special_tokens = True,\n",
    "                                            pad_to_max_length=True,\n",
    "                                            return_attention_mask=True,\n",
    "                                              truncation=True)\n",
    "        \n",
    "        input_ids.append(tokenized_text['input_ids'])\n",
    "        attention_masks.append(tokenized_text['attention_mask'])\n",
    "        token_type_ids.append(tokenized_text['token_type_ids'])\n",
    "    \n",
    "    return input_ids, attention_masks, token_type_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  동일하게  encode 함수를 정의해서 토큰화를 실시한다. 여기서는 token_type_ids 정보도 추출하는데, 이는 각 토큰의 문장 임베딩 정보를 포함하고 있다. 여기서는 리뷰가 한개씩 입력되지만, 원래 BERT모델은 두 개의 문장을 입력받기 때문에 동일한 구조로 사용하기 위해서 해당 정보도 추출한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습데이터 토큰화\n",
    "train_input_ids, train_attention_masks, train_token_type_ids = encode(X_train_texts, tokenizer)\n",
    " \n",
    "#테스트데이터 토큰화\n",
    "test_input_ids, test_attention_masks, test_token_type_ids = encode(X_test_texts, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33085"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT 모델 입력을 위한 형태로 처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#딕셔너리 형태로 변환해서 출력 \n",
    "def map_example_to_dict(input_ids, attention_masks, token_type_ids, label):\n",
    "    return {\n",
    "      \"input_ids\": input_ids,\n",
    "      \"token_type_ids\": token_type_ids,\n",
    "      \"attention_mask\": attention_masks,\n",
    "      }, label\n",
    "      \n",
    " #데이터를 BERT에 넣을 수 있는 형태로 변경 \n",
    "def data_encode(input_ids_list, attention_mask_list, token_type_ids_list, label_list):\n",
    "    return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, token_type_ids_list, label_list)).map(map_example_to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    " \n",
    "# 학습 데이터셋 생성\n",
    "train_data_encoded = data_encode(train_input_ids, train_attention_masks, train_token_type_ids, y_train).shuffle(10000).batch(BATCH_SIZE)\n",
    " \n",
    "# 테스트 데이터셋 생성\n",
    "test_data_encoded = data_encode(test_input_ids, test_attention_masks, test_token_type_ids, y_test).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertModel.from_pretrained('bert-base-uncased', output_hidden_states = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertForSequenceClassification\n",
    "# 모델 정의\n",
    "BERT_model = TFBertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  60/1034 [>.............................] - ETA: 3:10:12 - loss: 0.2582 - accuracy: 0.9245"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 모델 훈련\u001b[39;00m\n\u001b[0;32m      8\u001b[0m NUM_EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m----> 9\u001b[0m history \u001b[38;5;241m=\u001b[39m BERT_model\u001b[38;5;241m.\u001b[39mfit(train_data_encoded, epochs\u001b[38;5;241m=\u001b[39mNUM_EPOCHS, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, validation_data\u001b[38;5;241m=\u001b[39mtest_data_encoded)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:1170\u001b[0m, in \u001b[0;36mTFPreTrainedModel.fit\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(keras\u001b[38;5;241m.\u001b[39mModel\u001b[38;5;241m.\u001b[39mfit)\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1169\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m convert_batch_encoding(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py:1804\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1796\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1798\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1801\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1802\u001b[0m ):\n\u001b[0;32m   1803\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1804\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1806\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    868\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    870\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[0;32m    871\u001b[0m   )\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 옵티마이저, 손실 함수, 평가 메트릭 설정\n",
    "optimizer = tf.keras.optimizers.Adam(1e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "BERT_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "# 모델 훈련\n",
    "NUM_EPOCHS = 10\n",
    "history = BERT_model.fit(train_data_encoded, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, validation_data=test_data_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train','val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정확도 확인 \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train','val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출처\n",
    "# https://yeong-jin-data-blog.tistory.com/entry/BERT%EB%A1%9C-%EC%98%81%ED%99%94-%EB%A6%AC%EB%B7%B0-%EA%B0%90%EC%84%B1-%EB%B6%84%EC%84%9D%ED%95%98%EA%B8%B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT model (중지)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert 사용에 필요한 모듈 불러오기\n",
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, Adafactor, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT는 문장의 앞에 [CLS]를 붙이고, 끝에는 [SEP]을 붙여 처리를 해 주어야한다. 그러므로 반복문 등을 활용하여 처리해 주어야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['색감 표현 떨어져 화질 흐릿 배터리 용량 작아 쓸 때 답답',\n",
       " '미리 문해 잘 받았습니다 디자인 기대했던것 만큼 세련되서 좋아요 배터리 단다고 해서 걱정 했는데 진짜 사용 시간 짧네요 핑골 색상 선택 하길 했어요 고급스러워요',\n",
       " '주변 제품 평이 넘 좋아서 샀는데 다른 제품 비해 확실히 편해서 맘 들어요 모르고 샀는데 받고 보니 키 보드 마우스 셋트 구성 상품 이었네요 구성 최고',\n",
       " '사은 품 받은 케이스 귀여워요 주문 하는 바람 쪼금 더 비싼 가격 산 게 아쉽네요 또 달리다가 멈출 때 삐 소리 나 게 거슬려서 좀 별로 예전 쓰던 제품 좋아요',\n",
       " '화면 선명하게 잘 보입니다 녹화 것 훨 보기 좋아 만족해요 안전 운전 멘트 나오는것도 마음 들어요']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[CLS] 색감 표현 떨어져 화질 흐릿 배터리 용량 작아 쓸 때 답답 [SEP]'],\n",
       " ['[CLS] 미리 문해 잘 받았습니다 디자인 기대했던것 만큼 세련되서 좋아요 배터리 단다고 해서 걱정 했는데 진짜 사용 시간 짧네요 핑골 색상 선택 하길 했어요 고급스러워요 [SEP]'],\n",
       " ['[CLS] 주변 제품 평이 넘 좋아서 샀는데 다른 제품 비해 확실히 편해서 맘 들어요 모르고 샀는데 받고 보니 키 보드 마우스 셋트 구성 상품 이었네요 구성 최고 [SEP]'],\n",
       " ['[CLS] 사은 품 받은 케이스 귀여워요 주문 하는 바람 쪼금 더 비싼 가격 산 게 아쉽네요 또 달리다가 멈출 때 삐 소리 나 게 거슬려서 좀 별로 예전 쓰던 제품 좋아요 [SEP]'],\n",
       " ['[CLS] 화면 선명하게 잘 보입니다 녹화 것 훨 보기 좋아 만족해요 안전 운전 멘트 나오는것도 마음 들어요 [SEP]']]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT에 맞는 Tag 달아주기\n",
    "bert_text = []\n",
    "\n",
    "for i in X_train_texts:\n",
    "  bert = [\"[CLS] \" + str(i) + \" [SEP]\"]\n",
    "  bert_text.append(bert)\n",
    "\n",
    "bert_text[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이전 단계에서 이미 토큰화된 것을 사용하면 좋겠지만, 위와 같이 CLS 및 SEP 태그를 달아주어야 했기 때문에, 최초의 데이터를 활용했다. 이번에는 Bert multilingual 모델에 있는 tokenizer를 활용하여 토큰화한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9163efc60dc04d85a7404e48f00a93f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wisei\\miniconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\wisei\\.cache\\huggingface\\hub\\models--bert-base-multilingual-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5826a77604d74fab87da7d1260a45959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d392b2f781849b5857d7b79dcda2b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348608f169ff40aab85cf64af54a1406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['[CLS]', '색', '##감', '표', '##현', '떨', '##어져', '화', '##질', '흐', '##릿', '배', '##터', '##리', '용', '##량', '작', '##아', '쓸', '때', '답', '##답', '[SEP]'], ['[CLS]', '미', '##리', '문', '##해', '잘', '받', '##았', '##습', '##니다', '디', '##자인', '기', '##대', '##했던', '##것', '만', '##큼', '세', '##련', '##되', '##서', '좋', '##아', '##요', '배', '##터', '##리', '단', '##다고', '해', '##서', '걱', '##정', '했', '##는데', '진', '##짜', '사', '##용', '시', '##간', '짧', '##네', '##요', '핑', '##골', '색', '##상', '선', '##택', '하', '##길', '했', '##어', '##요', '고', '##급', '##스', '##러', '##워', '##요', '[SEP]'], ['[CLS]', '주', '##변', '제', '##품', '평', '##이', '넘', '좋', '##아', '##서', '샀', '##는데', '다른', '제', '##품', '비해', '확', '##실', '##히', '편', '##해서', '맘', '들어', '##요', '모', '##르고', '샀', '##는데', '받고', '보', '##니', '키', '보', '##드', '마', '##우스', '셋', '##트', '구', '##성', '상', '##품', '이', '##었', '##네', '##요', '구', '##성', '최고', '[SEP]'], ['[CLS]', '사', '##은', '품', '받은', '케', '##이스', '귀', '##여', '##워', '##요', '주', '##문', '하는', '바', '##람', '[UNK]', '더', '비', '##싼', '가', '##격', '산', '게', '아', '##쉽', '##네', '##요', '또', '달리', '##다가', '멈', '##출', '때', '[UNK]', '소', '##리', '나', '게', '거', '##슬', '##려', '##서', '좀', '별', '##로', '예', '##전', '쓰', '##던', '제', '##품', '좋', '##아', '##요', '[SEP]'], ['[CLS]', '화', '##면', '선', '##명', '##하게', '잘', '보', '##입', '##니다', '녹', '##화', '것', '훨', '보', '##기', '좋', '##아', '만', '##족', '##해', '##요', '안', '##전', '운', '##전', '멘', '##트', '나', '##오는', '##것', '##도', '마', '##음', '들어', '##요', '[SEP]'], ['[CLS]', '알', '##아', '##보', '##고', '비', '##교', '해', '##봤', '##지만', '제', '##품', '가', '##격', '대', '##비', '성', '##능', '좋', '##아', '##요', '문서', '작', '##업', '동', '##영', '##상', '등', '주로', '보', '##기', '충', '##분', '##한', '사', '##양', '요', '[SEP]'], ['[CLS]', '빠', '##른', '배', '##송', '좋', '##고', '불', '##량', '없', '##고', '작', '##동', '되는', '품', '##질', '좋은', '제', '##품', '할', '##인', '행', '##사', '가', '##격', '착', '##하게', '잘', '사', '##서', '만', '##족', '##합', '##니다', '[SEP]'], ['[CLS]', '문', '##후', '바로', '도', '##착', '해', '좋', '##았', '##어', '##요', '음', '##질', '또', '##렷', '##하게', '음', '들', '##려', '좋', '##고', '이', '##정', '가', '##격', '이런', '품', '##질', '정', '##박', '대', '##박', '입', '##니다', '[SEP]'], ['[CLS]', '화', '##면', '크', '##기', '큰', '##게', '좋', '##아', '##서', '샀', '##지만', '역시', '커', '##서', '보고', '##있', '##음', '흐', '##뭇', '##합', '##니다', '색', '##상', '맘', '들어', '##서', '고', '##민', '했', '##어', '##요', '실', '##물', '색', '##상', '더', '예', '##뻐', '##요', '소', '##재', '만', '##졌', '##을', '때', '지', '##문', '묻', '##어', '##나', '##지', '않고', '넘', '좋', '##네', '##요', '속', '##도', '진', '##짜', '빠', '##르', '##네', '##요', '만', '##족', '##스', '##럽', '##습', '##니다', '[SEP]'], ['[CLS]', '라', '##벤', '##더', '색', '##상', '원', '##했', '##는데', '품', '##절', '블', '##랙', '샀', '##어', '##요', '아', '##쉽', '##네', '##요', '카', '##드', '할', '##인', '적', '##립', '##금', '써', '##서', '정', '##가', '싸', '##게', '구', '##입', '해', '##서', '위', '##안', '[UNK]', '가', '##격', '좋', '##아', '##요', '[SEP]']]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
    "tokenized_data = []\n",
    "for i in bert_text:\n",
    "  for j in i:\n",
    "    tokens = tokenizer.tokenize(j)\n",
    "    tokenized_data.append(tokens)\n",
    "\n",
    "print(tokenized_data[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이전 딥러닝 수업에서 padding이 매우 중요하다고 배웠다. 가장자리에 있는 데이터들이 1번만 사용되는 것을 막기 위해 기존 데이터에 0의 테두리를 두르는 것이다. 이 작업이 BERT 모델을 돌리기 위해서도 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['저'], ['음'], [], ['작'], ['게']]\n"
     ]
    }
   ],
   "source": [
    "tokenized_test_data = []\n",
    "for i in X_test_texts:\n",
    "  for j in i:\n",
    "    tokens = tokenizer.tokenize(j)\n",
    "    tokenized_test_data.append(tokens)\n",
    "\n",
    "print(tokenized_test_data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 9416, 105197, 9934, 30842, 9141, 65164, 9993, 48599, 10015, 118906, 9330, 21876, 12692, 9603, 44321, 9652, 16985, 9513, 9137, 9065, 118775, 102]\n"
     ]
    }
   ],
   "source": [
    "# padding\n",
    "input_ids = []\n",
    "for i in tokenized_data:\n",
    "  ids = tokenizer.convert_tokens_to_ids(i)\n",
    "  input_ids.append(ids)\n",
    "\n",
    "print(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9634]\n"
     ]
    }
   ],
   "source": [
    "input_ids_test = []\n",
    "for i in tokenized_test_data:\n",
    "  ids = tokenizer.convert_tokens_to_ids(i)\n",
    "  input_ids_test.append(ids)\n",
    "\n",
    "print(input_ids_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   101,   9416, 105197,   9934,  30842,   9141,  65164,   9993,\n",
       "        48599,  10015, 118906,   9330,  21876,  12692,   9603,  44321,\n",
       "         9652,  16985,   9513,   9137,   9065, 118775,    102,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 128\n",
    "input_ids = pad_sequences(input_ids, maxlen=max_len, dtype='long', truncating='post', padding='post')\n",
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9663,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_test = pad_sequences(input_ids_test, maxlen=max_len, dtype='long', truncating='post', padding='post')\n",
    "input_ids_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "attention_masks = []\n",
    "\n",
    "for ids in input_ids:\n",
    "  ids_mask = []\n",
    "  for id in ids:\n",
    "      masked = float(id>0)\n",
    "      ids_mask.append(masked)\n",
    "  attention_masks.append(ids_mask)\n",
    "    \n",
    "print(attention_masks[0])\n",
    "print(len(attention_masks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "attention_masks_test = []\n",
    "\n",
    "for ids in input_ids_test:\n",
    "  ids_mask = []\n",
    "  for id in ids:\n",
    "      masked = float(id>0)\n",
    "      ids_mask.append(masked)\n",
    "  attention_masks_test.append(ids_mask)\n",
    "    \n",
    "print(attention_masks_test[0])\n",
    "print(len(attention_masks_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_texts_cos = []\n",
    "y_cos = []\n",
    "\n",
    "for Score_change, RawText in zip(df2['Score_change'], df2['RawText']):\n",
    "  tokenized_comment = tokenize_korean_text_2(RawText)  # 위에서 만들었던 함수로 comment 쪼개기\n",
    "  X_texts_cos.append(tokenized_comment)\n",
    "  y_cos.append(1 if Score_change > 3.5 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델링을 위해서는 train 데이터와 validation 데이터를 분리해야한다. 테스트 데이터는 이미 분리되어있다. 다만 이후 모델의 fine-tuning을 위한 데이터와, 이후 모델링을 위해 tensor로 변환할 데이터를 분리해 주어야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    input_ids, y_train, random_state=42, test_size=0.2)\n",
    "\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n",
    "                                                       input_ids,\n",
    "                                                       random_state=42, \n",
    "                                                       test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train\u001b[38;5;241m.\u001b[39mshape, X_val\u001b[38;5;241m.\u001b[39mshape, y_train\u001b[38;5;241m.\u001b[39mshape, y_val\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26468, 128), (6617, 128))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26468,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array(y_train)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning과 Tensor로 사용할 데이터를 분리\n",
    "X_train_tune = X_train\n",
    "y_train_tune = y_train\n",
    "X_val_tune = X_val\n",
    "y_val_tune = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = input_ids_test\n",
    "y_test_tensor = test_data[\"label\"].values\n",
    "test_masks = attention_masks_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다음으로 input_ids, 타깃 라벨, masking을 PyTorch로 변환해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_data_tf = tf_vectorizer.transform(X_texts_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_data_predictions = model.predict(cos_data_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text, prediction in zip(X_texts_cos, cos_data_predictions):\n",
    "    sentiment = \"Positive\" if prediction == 1 else \"Negative\"\n",
    "    print(f'Text: \"{text}\", Predicted Sentiment: {sentiment}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_data_accuracy = accuracy_score(y_cos, cos_data_predictions)\n",
    "print(f'Accuracy on new data: {cos_data_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='label', data=df2)\n",
    "plt.title('negative: 0, positive: 1')\n",
    "plt.xlabel('label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch로 변환\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train)\n",
    "y_train_tensor = torch.tensor(y_train)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "X_val_tensor = torch.tensor(X_val)\n",
    "y_val_tensor = torch.tensor(y_val)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = torch.tensor(X_test_tensor)\n",
    "y_test_tensor = torch.tensor(y_test_tensor)\n",
    "test_masks = torch.tensor(attention_masks_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이번에는 배치 사이즈를 지정한다. 주로 큰 사이즈를 설정해보고, VRAM 에러 메시지가 난다면, 더 작은 사이즈로 줄여나간다. 8의 배수로 설정하는 것이 일반적이다. 한 블로그를 참조[2]해보니, 32일 때 가장 좋은 성능이 나왔다고 한다. 그래서 이를 batch_size의 값으로 설정했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train = TensorDataset(X_train_tensor, train_masks, y_train_tensor)\n",
    "train_sampler = RandomSampler(train)\n",
    "\n",
    "val = TensorDataset(X_val_tensor, validation_masks, y_val_tensor)\n",
    "val_sampler = SequentialSampler(val)\n",
    "\n",
    "\n",
    "test = TensorDataset(X_test_tensor, test_masks, y_test_tensor)\n",
    "test_sampler = RandomSampler(test)\n",
    "\n",
    "train_dataloader = DataLoader(train, sampler=train_sampler, batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val, sampler=val_sampler, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
